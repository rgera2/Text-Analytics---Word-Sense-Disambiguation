{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ontological WSD","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgDyfbVFjCMn","executionInfo":{"status":"ok","timestamp":1606784721152,"user_tz":360,"elapsed":4998,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"85f15e03-cdb2-455e-c9fb-340d7dc9e1b8"},"source":["import pandas as pd\n","from collections import  Counter\n","import re\n","\n","\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","from gensim.parsing.preprocessing import remove_stopwords\n","\n","import spacy\n","sp = spacy.load('en_core_web_sm')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miELvJby6kCU","executionInfo":{"status":"ok","timestamp":1606784746937,"user_tz":360,"elapsed":25767,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"7b93b1d4-b07d-4f1a-8afd-f8b81fc4df0c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"9ktCIWfw6kFr","executionInfo":{"status":"ok","timestamp":1606784749863,"user_tz":360,"elapsed":849,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"39bf372e-ac0a-4114-c6a3-0c3a8ddde904"},"source":["import os\n","os.chdir('/content/drive/Shareddrives/Text Analytics/HW2/')\n","os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/Shareddrives/Text Analytics/HW2'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYUtZF-y6R8j","executionInfo":{"status":"ok","timestamp":1606784753044,"user_tz":360,"elapsed":1118,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"2c2ec106-0604-4195-b8eb-bfb15ba7df41"},"source":["from lxml import etree, objectify\n","\n","# Read the dictionary file.\n","Parser = objectify.makeparser(recover=True)\n","Tree = objectify.fromstring(''.join(open('dictionary.xml').readlines()), Parser)\n","\n","\n","# function: \n","def getSenses(word, pos):\n","    global Tree\n","    item = Tree.xpath(\"//lexelt[@item='%s.%s']\" % (word, pos))    \n","    senses = []\n","    for sense in item[0].getchildren():\n","        senses.append(dict(zip(sense.keys(), sense.values())))\n","    return senses\n","\n","\n","# function:\n","def getSense(word, pos, sense_id):\n","    global Tree\n","    sense = Tree.xpath(\"//lexelt[@item='%s.%s']/sense[@id='%d']\" % (word, pos, sense_id))\n","    return dict(zip(sense[0].keys(), sense[0].values()))\n","\n","\n","# Example\n","print(getSense('begin', 'v', 2))\n","print(getSenses('begin', 'v'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'id': '2', 'wordnet': '1,8,5', 'gloss': 'initiate an undertaking', 'examples': \"They'll begin their tour with a concert in London. | You should begin the stew now so it will have four hours to simmer. | The government is beginning to protect the coral reefs of that island. | He was just beginning a novel when the phone rang. | Acme Tire Co. began offering their employees health insurance. | John has begun to take them seriously. | She began ballet at age four.\"}\n","[{'id': '1', 'wordnet': '2,3,5,6,7', 'gloss': 'start, have an initial point ', 'examples': \"Prices for these homes begin at $250,000 | The war began on a Thursday. | She began to feel sick. | When life began was there oxygen in the atmosphere? | The novel begins with a shipwreck at sea. | It's beginning to look like rain. | His property begins at the fence.\"}, {'id': '2', 'wordnet': '1,8,5', 'gloss': 'initiate an undertaking', 'examples': \"They'll begin their tour with a concert in London. | You should begin the stew now so it will have four hours to simmer. | The government is beginning to protect the coral reefs of that island. | He was just beginning a novel when the phone rang. | Acme Tire Co. began offering their employees health insurance. | John has begun to take them seriously. | She began ballet at age four.\"}, {'id': '3', 'wordnet': '4', 'gloss': 'make a locution, speak', 'examples': ''}, {'id': '4', 'wordnet': '9', 'gloss': 'partially attain', 'examples': \"The rent you could get for that place wouldn't begin to cover the mortgage and taxes. | Can those refugees even begin to hope they'll be granted asylum? | I couldn't begin to tell you all the ways she has contributed to this club.\"}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IBeTz6gD6SLO"},"source":["temp=getSenses('begin', 'v')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5vn32M9LIf5","executionInfo":{"status":"ok","timestamp":1606784757832,"user_tz":360,"elapsed":280,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"77627d0d-56d6-4e41-b731-a340417d1736"},"source":["temp[0].keys()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['id', 'wordnet', 'gloss', 'examples'])"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6KmFx3udMmMb","executionInfo":{"status":"ok","timestamp":1606784759549,"user_tz":360,"elapsed":330,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"d2862523-cb58-47ad-e8d1-de210b587b7c"},"source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XMLPbZh-XQBg","executionInfo":{"status":"ok","timestamp":1606784763383,"user_tz":360,"elapsed":420,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"be0416c5-9b07-41e0-b9ae-2aaa369835cf"},"source":["print(getSenses('work', 'v'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'id': '1', 'wordnet': '1,2,6,8,10,12', 'gloss': 'exert oneself in an activity', 'examples': \"He is working hard to bring up his grade. | They worked on a farm growing up. | Those men will work for minimum wage. | They work us hard in that gym class. | The salesman works the Midwest. | Don't work those children so hard. | Her fingers worked with incredible speed. | She worked at the algebra problems until she'd solved them all. | At the end of sentence, he had worked off his debt to society. | Please be quiet while I work on the taxes.\"}, {'id': '2', 'wordnet': '3,4,11', 'gloss': 'perform, function, behave', 'examples': \"How will the parachute actually work when deployed? | This old radio doesn't work anymore. | That drug has worked miracles for those with arthritis.\"}, {'id': '3', 'wordnet': '5,13,14,20,22', 'gloss': 'shape, form, handle', 'examples': \"The artist taught them to work different kinds of clay. | We'll have to work this hard soil a lot before planting lettuce. | The dough should work easily when kneading; if not, add more water. | He gradually worked the metal into a sword. | Work the dough until it is smooth and glossy. | Next, work in the butter. | Try to work some jokes into your speech.\"}, {'id': '4', 'wordnet': '7,9,21,27', 'gloss': 'proceed, move, position', 'examples': 'I worked my way carefully around the broken glass. | Start from the bottom and work towards the top. | Slowly we worked the big rock onto the flatbed of the truck. | The screw worked free. | He knows how to work himself out of a jam.'}, {'id': '5', 'wordnet': '15,18,19,23', 'gloss': 'control, exploit, act upon', 'examples': \"She worked on her friends to support the political candidate. | The rock musician worked the crowd of young girls into a frenzy. | Politicians know how to work a crowd. | You've got to learn how to work the system.\"}, {'id': '6', 'wordnet': '16,17', 'gloss': 'operate', 'examples': \"We'll work the phones tonight for the fund raiser. | Can you work an electric drill?\"}, {'id': '7', 'wordnet': '25,26', 'gloss': 'ferment', 'examples': 'The vintner worked the wine in big oak vats. | The wine worked.'}, {'id': '8', 'wordnet': '24', 'gloss': 'solve, figure out', 'examples': \"He couldn't work the second problem on the test. | They worked out a plan that should succeed. | The fees work out to less than $100. | Let's work through this problem together.\"}, {'id': '9', 'wordnet': '', 'gloss': 'idioms', 'examples': \"Don't worry. Things will all work out in the end. | He works out at the gym every day. | Those thugs worked him over pretty bad and now he's in the hospital. | I've really worked up an appetite. | The team worked up an ad for the client in record time.\"}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W9mlbfGFTQu6"},"source":["temp=getSenses('come', 'v')\n","import string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XrsPI16ZXr9z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606784768311,"user_tz":360,"elapsed":711,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"f51fb992-3da7-4ee5-8749-464b9331e92f"},"source":["nltk.download('wordnet')\n","from nltk import wordnet as wn\n","from nltk.stem import WordNetLemmatizer \n","lemmatizer = WordNetLemmatizer()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xKAyW7lv-nhC"},"source":["from nltk.util import ngrams\n","import string\n","import math"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4I_f5LzNBl5"},"source":["def data_cleaning(tokenized_data):\n","  ds = tokenized_data\n","  for idx,j in enumerate(ds):\n","    if j not in stopwords.words():\n","      j = j.translate(str.maketrans('', '', string.punctuation+'0123456789'))  #### removing punctuations\n","      j = j.lower() #### lowering all words ######\n","      j = lemmatizer.lemmatize(j) #### lemmatize noun\n","      j = lemmatizer.lemmatize(j,'v') #### lemmatize verb\n","      ds[idx] = j\n","  ds = [j for j in ds if not j in stopwords.words()]\n","  ds = list(filter(None, ds)) ### filter out empty tokens if any\n","  return ds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjw4Osw1oM9j","executionInfo":{"status":"ok","timestamp":1606784789421,"user_tz":360,"elapsed":1901,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"060a5c03-c9c8-4866-ade7-1e0087ceca53"},"source":["### checking\n","data_cleaning(['control,', 'exploited,', 'act', 'upon', 'She', 'worked', 'on', 'her', 'friends', 'to', 'support'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['control', 'exploit', 'act', 'upon', 'work', 'friend', 'support']"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"IHvb0wSPtzYU"},"source":["# Original lesk (modified) - high rewards for consecutive overlaps"]},{"cell_type":"code","metadata":{"id":"uAHyqHvjU7aj"},"source":["def original_lesk(sentence,word,pos,modified=False):\n","  max_common = 0\n","  id=0\n","  sense = None\n","  try:\n","    temp=getSenses(word,pos)  #### sense from dictionary\n","    context = sentence#.split() ##### any random sentence or data\n","    #print(context)\n","    context = context.lower().translate(str.maketrans('', '', string.punctuation+'0123456789'))\n","    context_tags = nltk.pos_tag(context.split())   ### pos tags of those words which are not provided before data cleaning\n","    con = []\n","    for i in range(len(context_tags)):\n","      l = context_tags[i]\n","      k = [j.split() for j in l[1]][0]\n","      x = l[0].lower().translate(str.maketrans('', '', string.punctuation+'0123456789'))\n","      x = lemmatizer.lemmatize(x)\n","      x = lemmatizer.lemmatize(x,'v')\n","      d = dict(word=x,pos=k[0].lower())\n","      con.append(d)\n","    #print(con)\n","    for j in range(len(temp)):\n","      score=0\n","      lesk_dict = []\n","      ### word-meaning of the word###\n","      lesk_dict+= temp[j][\"gloss\"].split()\n","      temp_sense = temp[j][\"gloss\"]   ### temporary sense ####\n","      #### using examples as well\n","      x = [l.split() for l in temp[j]['examples'].split('|')]\n","      examples = [item for sublist in x for item in sublist] ### examples split\n","      ##### using gloss + examples\n","      lesk_dict += examples\n","      lesk_dict = data_cleaning(lesk_dict)\n","      #print(lesk_dict)\n","      for k in range(len(con)):\n","        if con[k][\"word\"] != word:\n","          #print(con[k][\"word\"])\n","          try:\n","            ex = getSenses(con[k]['word'],con[k]['pos'])\n","            #print(ex)\n","            new_dict = []\n","            ### word-meaning of the word###\n","            for l in range(len(ex)):\n","              new_dict+= ex[l][\"gloss\"].split()\n","            #new_dict+= ex[i][\"gloss\"].split()\n","            #print(new_dict)\n","            #### using examples as well\n","            t=[]\n","            for l in range(len(ex)):\n","              t+= ex[l][\"examples\"].split('|')\n","            new_x = [l.split() for l in t]\n","            new_examples = [item for sublist in new_x for item in sublist] ### examples split\n","            ##### using gloss + examples\n","            new_dict += new_examples\n","            #print(new_dict)\n","            new_dict = data_cleaning(new_dict)\n","            #print(new_dict)\n","            #### score computation from overlapping\n","            score_set = set(lesk_dict).intersection(new_dict) #### checking common words in gloss and examples\n","            #print(score_set)\n","            score += len(score_set)\n","            if modified:\n","              score_set_bi = set(list(ngrams(lesk_dict, 2))).intersection(list(ngrams(new_dict, 2))) #### checking common bigrams in gloss and examples\n","              score+= math.pow(len(score_set_bi),2)   #### rewarding consecutive overlaps by giving score which should be square of such overlaps\n","            #print(score_set,score)\n","          except IndexError:\n","            pass\n","      temp_id = temp[j][\"id\"]\n","      if score > max_common:\n","        sense = temp_sense   #### updating sentence with most number of overlapping words\n","        id = temp_id\n","        max_common = score\n","  except (IndexError, UnboundLocalError) as e:\n","    sense,id=(None,0)\n","  return sense,id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IggOxl43R1Bt","executionInfo":{"status":"ok","timestamp":1606782043104,"user_tz":360,"elapsed":13242,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"ba880992-4e58-4c1c-fa1f-15666559a1b4"},"source":["# random test\n","sent = 'working by doing things in mexico'\n","original_lesk(sent,'work','v',modified=True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('exert oneself in an activity', '1')"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"6sKvJrZi2hPl"},"source":["Reading Training data"]},{"cell_type":"code","metadata":{"id":"-_Im4uNNr8So"},"source":["def file_dataframe(filename):\n","  input_string = os.getcwd() + '/'+str(filename)\n","  open_file = open(input_string, 'r')\n","  read_data = open_file.readlines()\n","  return read_data "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKU0tHRh4A3b","executionInfo":{"status":"ok","timestamp":1606784795248,"user_tz":360,"elapsed":1067,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"23cedc17-d210-4f73-d0b5-3a846150ded6"},"source":["### reading training data\n","train = file_dataframe('train.data')\n","head = list(train)\n","head[0:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"affect.v | 1 | The Mahatma , or `` great souled one , '' instigated several campaigns of passive resistance against the British government in India . Unfortunately , according to Webster 's Biographical Dictionary , `` His policies went beyond his control and resulted ... in riots and disturbances '' and later a renewed campaign of civil disobedience `` resulted in rioting and a second imprisonment . '' I am not a proponent of everything Gandhi did , but some of his law breaking was justified because India was then under occupation by a foreign power , and Indians were not able to participate fully in decisions that vitally %% affected %% them . It is difficult , however , to justify civil disobedience , non-violent or not , where citizens have full recourse to the ballot box to effect change . Where truly representative governments are safeguarded by constitutional protections of human rights and an independent judiciary to construe those rights , there is no excuse for breaking the law because some individual or group disagrees with it .\\n\",\n"," 'affect.v | 1 | Some U.S. allies are complaining that President Bush is pushing conventional-arms talks too quickly , creating a risk that negotiators will make errors that could %% affect %% the security of Western Europe for years . Concerns about the pace of the Vienna talks -- which are aimed at the destruction of some 100,000 weapons , as well as major reductions and realignments of troops in central Europe -- also are being registered at the Pentagon . Mr. Bush has called for an agreement by next September at the latest .\\n',\n"," \"affect.v | 1 | What 's more , he said , `` transactions are taking a much longer time to conclude and many fall apart for lack of financing '' and more stringent scrutiny by state courts . Lawyers also say an erratic stock market and uncertain financing conditions have sharply reduced the number of lucrative big deals likely to be proposed . Still , some lawyers say the mergers slowdown has n't %% affected %% foreign buyers as much as domestic ones . `` We just took another floor for our London offices , '' said Joseph Flom of the New York firm of Skadden , Arps , Slate , Meagher & Flom . Davis Polk & Wardwell also said its international clients are keeping mergers and acquisitions partners busy .\\n\"]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"94p1wtKhhgCd"},"source":["###### manipulating in same format as in dictionary\n","def data_handling(filename):\n","  train = file_dataframe(filename)\n","  head = list(train)\n","  text=[]\n","  for i in range(len(head)):\n","    word = head[i].split('|')[0].split('.')[0].strip()\n","    pos= head[i].split('|')[0].split('.')[1].strip()\n","    id = head[i].split('|')[1].strip()\n","    example = head[i].split('|')[2]\n","    text.append(dict(id = id,word=word,pos=pos,examples=example))\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RoRhFq-71Lhs"},"source":["training_text = data_handling(\"train.data\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzMu3UNUA7n3","executionInfo":{"status":"ok","timestamp":1606784800571,"user_tz":360,"elapsed":723,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"8de73d19-680f-4311-adba-a2e05d36eda1"},"source":["validation_text = data_handling(\"validate.data\")\n","len(validation_text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["933"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"EKjnPhH6uWkr"},"source":["# Checking performance of Original Lesk on validation data"]},{"cell_type":"code","metadata":{"id":"hEs0q7PTud6h"},"source":["########### Actual Sense Prediction #######\n","def actual_sense(data):\n","  actual_id =[]\n","  for i in range(len(data)):\n","    actual_id.append(data[i]['id'])\n","  return actual_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZUSe03IBPjv"},"source":["############ Sense Prediction Function ##############\n","def prediction(data,corpusLesk=False,simpleLesk=False,originalLesk=False,modified=True):\n","  predicted_id=[]\n","  for i in range(len(data)):\n","    if corpusLesk:\n","      sense,pred_id = corpus_lesk(data[i][\"examples\"],data[i]['word'],data[i]['pos'],modified)\n","    elif simpleLesk:\n","      sense,pred_id = simple_lesk(data[i][\"examples\"],data[i]['word'],data[i]['pos'],modified)\n","    elif originalLesk:\n","      sense,pred_id = original_lesk(data[i][\"examples\"],data[i]['word'],data[i]['pos'],modified)\n","    predicted_id.append(pred_id)\n","    if i%50==0:\n","      print(i)\n","  return predicted_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXg7kztAvYX4"},"source":["###### Warning !!! Might take 45-50 minutes to run ###############\n","given_sense = actual_sense(validation_text)\n","pred_sense = prediction(validation_text,originalLesk=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaxAlO51vYX4"},"source":["from sklearn.metrics import confusion_matrix\n","cm_simple=confusion_matrix(given_sense,pred_sense)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrbqlkzSvYX4","executionInfo":{"status":"ok","timestamp":1606783071098,"user_tz":360,"elapsed":622,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"dc829367-4cc3-48d4-9dca-662a5f28a5dc"},"source":["cm_simple.diagonal().sum()/sum(cm_simple).sum()*100    ##### Accuracy ####"],"execution_count":null,"outputs":[{"output_type":"stream","text":["41.102301\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9YHsVxA87WLN"},"source":["# Simple Lesk"]},{"cell_type":"code","metadata":{"id":"SK1dSoMx3lyv"},"source":["def simple_lesk(sentence,word,pos,modified=False):\n","  max_common = 0\n","  id=0\n","  sense = None\n","  try:\n","    temp=getSenses(word,pos)  #### sense from dictionary\n","    context = sentence.split() ##### any random sentence or data\n","    context = data_cleaning(context) #### cleaning data\n","    for i in range(len(temp)):\n","      lesk_dict = []\n","      ### word-meaning of the word###\n","      lesk_dict+= temp[i][\"gloss\"].split()\n","      temp_sense = temp[i][\"gloss\"]   ### temporary sense ####\n","      #### using examples as well\n","      x = [j.split() for j in temp[i]['examples'].split('|')]\n","      examples = [item for sublist in x for item in sublist] ### examples split\n","      ##### using gloss + examples\n","      lesk_dict += examples\n","      #print(lesk_dict)\n","      lesk_dict = data_cleaning(lesk_dict)\n","      #### score computation from overlapping\n","      score_set = set(lesk_dict).intersection(context) #### checking common words in gloss and examples\n","      score = len(score_set)\n","      if modified:\n","        score_set_bi = set(list(ngrams(lesk_dict, 2))).intersection(list(ngrams(context, 2))) #### checking common bigrams in gloss and examples\n","        score+= math.pow(len(score_set_bi),2)   #### rewarding consecutive overlaps by giving score which should be square of such overlaps\n","      #print(score_set,score_set_bi,score)\n","      temp_id = temp[i][\"id\"]\n","      if score > max_common:\n","        sense = temp_sense   #### updating sentence with most number of overlapping words\n","        id = temp_id\n","        max_common = score\n","  except IndexError:\n","    sense,id=(None,0)\n","  return sense,id"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jdjw7HhyBS3h"},"source":["# Checking performance of Simple Lesk (basic+modified) on validation data"]},{"cell_type":"markdown","metadata":{"id":"TPnSTSSXLHqN"},"source":["Simple Lesk with modified version which takes into account consecutive overlaps"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTgi4hALEQWc","executionInfo":{"status":"ok","timestamp":1606654125752,"user_tz":360,"elapsed":1926778,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"bb0445c8-7896-4b9d-b2a0-7b18a5c59457"},"source":["###### Warning !!! Might take 15-16 minutes to run ###############\n","given_sense = actual_sense(validation_text)\n","pred_sense = prediction(validation_text,simpleLesk=True,modified=False) ### Simple lesk basic ###"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","50\n","100\n","150\n","200\n","250\n","300\n","350\n","400\n","450\n","500\n","550\n","600\n","650\n","700\n","750\n","800\n","850\n","900\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gtcp5WIvE4uj"},"source":["from sklearn.metrics import confusion_matrix\n","cm_simple=confusion_matrix(given_sense,pred_sense)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3oIMAl8GE4uk","executionInfo":{"status":"ok","timestamp":1606654126186,"user_tz":360,"elapsed":348,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"a8b06e05-d675-4459-ce5b-816a98e097a7"},"source":["cm_simple.diagonal().sum()/sum(cm_simple).sum()*100    ##### Accuracy ####"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["49.30332261521972"]},"metadata":{"tags":[]},"execution_count":306}]},{"cell_type":"markdown","metadata":{"id":"UMHn0ERp7163"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"6LxZQvu772GE"},"source":["Simple Lesk modified with high reward to consecutive overlaps"]},{"cell_type":"code","metadata":{"id":"UYDZ4x9Y7-rx"},"source":["###### Warning !!! Might take 15-16 minutes to run ###############\n","given_sense = actual_sense(validation_text)\n","pred_sense = prediction(validation_text,simpleLesk=True,modified=True) ### Simple lesk modified ###"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LmUZyIa97-xQ"},"source":["from sklearn.metrics import confusion_matrix\n","cm_simple=confusion_matrix(given_sense,pred_sense)\n","cm_simple"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbnZH0D37-6J","executionInfo":{"status":"ok","timestamp":1606656117069,"user_tz":360,"elapsed":392,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"21835224-db43-446a-a568-45a9893ea166"},"source":["cm_simple.diagonal().sum()/sum(cm_simple).sum()*100    ##### Accuracy ####"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["49.51768488745981"]},"metadata":{"tags":[]},"execution_count":309}]},{"cell_type":"markdown","metadata":{"id":"i1GPhVaq8mH9"},"source":["# Applying Simple Modified Lesk on Test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSrmHDAn1wD-","executionInfo":{"status":"ok","timestamp":1606784876964,"user_tz":360,"elapsed":1370,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"89dc7849-3d69-4df5-aab6-a1a366a377bc"},"source":["test_text = data_handling(\"test.data\")\n","len(test_text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3918"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"TCmhwQJrPKvb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606793332538,"user_tz":360,"elapsed":8145958,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"d1e38a9a-e54b-4689-e8d4-b31906412498"},"source":["given_sense_test = actual_sense(test_text)\n","pred_test_simple = prediction(test_text,simpleLesk=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n","50\n","100\n","150\n","200\n","250\n","300\n","350\n","400\n","450\n","500\n","550\n","600\n","650\n","700\n","750\n","800\n","850\n","900\n","950\n","1000\n","1050\n","1100\n","1150\n","1200\n","1250\n","1300\n","1350\n","1400\n","1450\n","1500\n","1550\n","1600\n","1650\n","1700\n","1750\n","1800\n","1850\n","1900\n","1950\n","2000\n","2050\n","2100\n","2150\n","2200\n","2250\n","2300\n","2350\n","2400\n","2450\n","2500\n","2550\n","2600\n","2650\n","2700\n","2750\n","2800\n","2850\n","2900\n","2950\n","3000\n","3050\n","3100\n","3150\n","3200\n","3250\n","3300\n","3350\n","3400\n","3450\n","3500\n","3550\n","3600\n","3650\n","3700\n","3750\n","3800\n","3850\n","3900\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"frsEpJs6XJNS","executionInfo":{"status":"ok","timestamp":1606793610424,"user_tz":360,"elapsed":297,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"1f538704-9733-406d-f865-9e1ed356e14d"},"source":["pred_test_simple[0:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['2', '1', '2', '2', '2', '1', '3', '1', '1', '1']"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"LKDR1BA1P1-o"},"source":["text_file = open(\"test_simple_lesk.data\", \"w\")\n","for i in range(len(test_text)):\n","  test_text[i][\"id\"] = pred_test_simple[i]\n","  line = test_text[i]['word']+'.'+test_text[i]['pos']+\" | \"+str(test_text[i]['id'])+\" | \"+test_text[i]['examples']\n","  text_file.write(line)\n","text_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94_cSIlcQvrr","executionInfo":{"status":"ok","timestamp":1606793824525,"user_tz":360,"elapsed":263,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"32a5dc64-2972-498c-9367-c234a2c97b56"},"source":["len(file_dataframe('test_simple_lesk.data'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3918"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"fzw5IQ63RCfY","executionInfo":{"status":"ok","timestamp":1606389570920,"user_tz":360,"elapsed":532,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"d5c5868a-c394-4c67-cf71-d199e2e24448"},"source":["test_text[0]['word']+'.'+test_text[0]['pos']+\" | \"+test_text[0]['id']+\" | \"+test_text[0]['examples']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"capital.n | 0 |  Influential members of the House Ways and Means Committee introduced legislation that would restrict how the new savings-and-loan bailout agency can raise capital , creating another potential obstacle to the government 's sale of sick thrifts . The bill , whose backers include Chairman Dan Rostenkowski ( D. , Ill. ) , would prevent the Resolution Trust Corp. from raising temporary working %% capital %% by having an RTC-owned bank or thrift issue debt that would n't be counted on the federal budget . The bill intends to restrict the RTC to Treasury borrowings only , unless the agency receives specific congressional authorization . `` Such agency ` self-help ' borrowing is unauthorized and expensive , far more expensive than direct Treasury borrowing , '' said Rep. Fortney Stark ( D. , Calif. ) , the bill 's chief sponsor .\\n\""]},"metadata":{"tags":[]},"execution_count":110}]},{"cell_type":"markdown","metadata":{"id":"51MaKSPpFQ9_"},"source":["#Corpus Lesk"]},{"cell_type":"code","metadata":{"id":"SL3y5wFlNBsf"},"source":["########### Augment train data with dictionary to train ##############\n","def merge_training(text,word,pos):\n","  n = list(filter(lambda x: (x['word'] == word and x['pos'] == pos), text))\n","  dict2 = {dct['id']:dct for dct in n}\n","  temp=getSenses(word,pos)\n","  out = []\n","  for d1 in temp:\n","    d = dict(**d1)\n","    if dict2.get(d1['id'])!=None:\n","      new_ex = d1['examples']+' | '+ dict2.get(d1['id'])['examples']\n","      d.update(examples=new_ex)\n","    else:\n","      d.update(dict2.get(d1['id'],{}))\n","    out.append(d)\n","  return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYPxb7SQ1DVc"},"source":["def corpus_lesk(sentence,word,pos,modified=False):\n","  max_common = 0\n","  id=0\n","  sense = None\n","  augmented_data = merge_training(training_text,word,pos)\n","  try:\n","    temp=augmented_data\n","    context = sentence.split() ##### any random sentence or data\n","    context = data_cleaning(context) #### cleaning data\n","    for i in range(len(temp)):\n","      lesk_dict = []\n","      ### word-meaning of the word###\n","      lesk_dict+= temp[i][\"gloss\"].split()\n","      temp_sense = temp[i][\"gloss\"]   ### temporary sense ####\n","      #### using examples as well\n","      x = [j.split() for j in temp[i]['examples'].split('|')]\n","      examples = [item for sublist in x for item in sublist] ### examples split\n","      ##### using gloss + examples\n","      lesk_dict += examples\n","      #print(lesk_dict)\n","      lesk_dict = data_cleaning(lesk_dict)\n","      #### score computation\n","      score_set = set(lesk_dict).intersection(context) #### checking common words in gloss and examples\n","      score = len(score_set)\n","      if modified:\n","        score_set_bi = set(list(ngrams(lesk_dict, 2))).intersection(list(ngrams(context, 2))) #### checking common bigrams in gloss ans examples\n","        score+= math.pow(len(score_set_bi),2)\n","      #print(score_set,score_set_bi,score)\n","      temp_id = temp[i][\"id\"]\n","      if score > max_common:\n","        sense = temp_sense   #### updating sentence with most number of overlapping words\n","        id = temp_id\n","        max_common = score\n","  except IndexError:\n","    sense,id=(None,0)\n","  return sense,id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qAqlbSPhNBqj","executionInfo":{"status":"ok","timestamp":1606688380483,"user_tz":360,"elapsed":12828,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"61b70054-bfa0-4aaa-e2e5-808535517ece"},"source":["###### random test\n","sent = 'come to Mexico'\n","corpus_lesk(sent,'come','v')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('move, travel, arrive', '1')"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"wQ_nz10SwlUm"},"source":["#### Checking performance of Corpus lesk"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTAgIqnBNBgD"},"source":["############## Warning !!!! Will take 30 minutes\n","pred_sense = prediction(validation_text,corpusLesk=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afpK4VSOeefQ"},"source":["from sklearn.metrics import confusion_matrix\n","cm=confusion_matrix(given_sense,pred_sense)\n","#cm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"elcN3fXXgqeJ","executionInfo":{"status":"ok","timestamp":1606693515507,"user_tz":360,"elapsed":354,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"9cf4809d-597d-40dc-e8bb-9996a8dd5b8d"},"source":["cm.diagonal().sum()/sum(cm).sum()*100"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["48.01714898177921"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"7RKEExRdNBdL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vxA36jSgY1VX"},"source":["# Running Corpus lesk and saving file"]},{"cell_type":"code","metadata":{"id":"TsGAqDmztN3z"},"source":["########## Warning !!!!! Will take 1.30 hours ############\n","pred_test_corpus = prediction(test_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eIuLn3FYYv29"},"source":["text_file = open(\"test_corpus_lesk.data\", \"w\")\n","for i in range(len(test_text)):\n","  test_text[i][\"id\"] = pred_test_corpus[i]\n","  line = test_text[i]['word']+'.'+test_text[i]['pos']+\" | \"+str(test_text[i]['id'])+\" | \"+test_text[i]['examples']\n","  text_file.write(line)\n","text_file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtNwciHCYv29","executionInfo":{"status":"ok","timestamp":1606794096346,"user_tz":360,"elapsed":291,"user":{"displayName":"Rahul Gera","photoUrl":"","userId":"11610824324271342547"}},"outputId":"05c7b2e6-6f33-4064-b7ca-e506ea7951d2"},"source":["len(file_dataframe('test_corpus_lesk.data'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3918"]},"metadata":{"tags":[]},"execution_count":43}]}]}